{
 "metadata": {
  "name": "",
  "signature": "sha256:0ad16866d975dbf5ebbf0bd905eb471dacea85829126b151c94f98045e65d007"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext autoreload\n",
      "\n",
      "%autoreload 2\n",
      "\n",
      "import theano as th\n",
      "from lasagne import easy\n",
      "import lasagne\n",
      "import lasagne.data\n",
      "\n",
      "# currently available datasets:\n",
      "from lasagne.datasets import mnist, fonts, notmnist, insects, ilc\n",
      "from theano import tensor as T"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The autoreload extension is already loaded. To reload it, use:\n",
        "  %reload_ext autoreload\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#To make a variable, specify the type of variable from the tensor\n",
      "#library.\n",
      " \n",
      "#We can have scalars.\n",
      "x=T.dscalar(name='scalar_x')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Note that the name is just a string that theano will use\n",
      "#to communicate to us about the variable.\n",
      "print x\n",
      "print x.type\n",
      "#We can also have vectors.\n",
      "v = T.dvector(name='vector_v')\n",
      "print v\n",
      "print v.type\n",
      "#And matrices.\n",
      "A = T.dmatrix(name='matrix_A')\n",
      "print A\n",
      "print A.type"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "scalar_x\n",
        "TensorType(float64, scalar)\n",
        "vector_v\n",
        "TensorType(float64, vector)\n",
        "matrix_A\n",
        "TensorType(float64, matrix)\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#We can also make new variables using standard mathematical operations.\n",
      "x_2 = x*x\n",
      "print x_2\n",
      "print x_2.type"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Elemwise{mul,no_inplace}.0\n",
        "TensorType(float64, scalar)\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#We can also make python functions which return new variables.\n",
      "def power(variable, n):\n",
      "    return variable**n\n",
      "x_10 = power(x,10)\n",
      "print x_10\n",
      "print x_10.type"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Elemwise{pow,no_inplace}.0\n",
        "TensorType(float64, scalar)\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#We can of course do standard linear algebra operations also.\n",
      "Av = T.dot(A,v)\n",
      "print Av\n",
      "print Av.type"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "dot.0\n",
        "TensorType(float64, vector)\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Of course when a variable is actually evaluated, you must \n",
      "#ensure that the dimensions are correct, or you will\n",
      "#get an error.\n",
      " \n",
      "#To see the value of a variable for a particular value of the variables\n",
      "#comprising it, we make a theano function.\n",
      "f = th.function([A,v], [Av])\n",
      "#The syntax is a list of input variables, and then a list of output variables."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#The python code takes a little longer to run initially, because thenao\n",
      "#compiles the function into C, but thereafter it will run extremely fast.\n",
      " \n",
      "#Let's try using the function.\n",
      "import numpy as np\n",
      "m=np.ones((2,2))\n",
      "print m\n",
      "vec = np.asarray([1,2])\n",
      "print vec\n",
      "print f(m,vec)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 1.  1.]\n",
        " [ 1.  1.]]\n",
        "[1 2]\n",
        "[array([ 3.,  3.])]\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Now we can try computing gradients.\n",
      "#First let's make a scalar variable by taking an inner product.\n",
      "w=T.dvector(name='w_vector')\n",
      "vTw = T.dot(v,w)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Now we take the gradient with respect to w.\n",
      "vTw_grad = T.grad(vTw,w)\n",
      "print vTw_grad\n",
      "print vTw_grad.type"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Elemwise{mul,no_inplace}.0\n",
        "TensorType(float64, vector)\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Now let's test it.\n",
      "vec1 = np.asarray([1,2])\n",
      "vec2 = np.asarray([0,0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#To evaulate a variable given inputs, there is another syntax\n",
      "#in additon to creating a thenano function.\n",
      "print vTw_grad.eval({w:vec1,v:vec2})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.  0.]\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Next we discuss theano's shared variables,\n",
      "#these differ from regular theano variables in that\n",
      "#theano variables only have a value within a theano function\n",
      "#whereas shared theano variables have a value independent of \n",
      "#being called in a function.\n",
      "w=T.shared(name='shared_matrix', value=np.ones((2,3)))\n",
      "print w\n",
      "print w.type\n",
      "print w.get_value()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "shared_matrix\n",
        "TensorType(float64, matrix)\n",
        "[[ 1.  1.  1.]\n",
        " [ 1.  1.  1.]]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:6: UserWarning: `tensor.shared` is deprecated. You should probably be using `theano.shared` instead (if you *really* intend to call `tensor.shared`, you can get rid of this warning by using `tensor._shared`).\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#You can also set a shared variable's value.\n",
      "w.set_value(np.zeros((2,3)))\n",
      "print w.get_value()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.  0.  0.]\n",
        " [ 0.  0.  0.]]\n"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#You can also have theano functions update shared variables,\n",
      "#we illustrate this with a silly example that updates a matrix\n",
      "#like in gradient descent.\n",
      "x=T.dvector('x')\n",
      "wx=T.dot(w,x)\n",
      "cost = wx.mean()\n",
      "cost_grad = T.grad(cost, w)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f=th.function(inputs=[x], outputs=[wx, cost], updates=[(w, w-0.1*cost_grad)])\n",
      "#Notice the syntax of updates argument, should be a list\n",
      "#of two tuples of the form: (variable_to_be_updated, updated_variable).\n",
      "print f([1,1,1])\n",
      "print w.get_value()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[array([ 0.,  0.]), array(0.0)]\n",
        "[[-0.05 -0.05 -0.05]\n",
        " [-0.05 -0.05 -0.05]]\n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import theano as th\n",
      "from theano import tensor as T\n",
      "from numpy import random as rng"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class AutoEncoder(object):\n",
      "    def __init__(self, X, hidden_size, activation_function,\n",
      "                 output_function):\n",
      "        #X is the data, an m x n numpy matrix\n",
      "        #where rows correspond to datapoints\n",
      "        #and columns correspond to features.\n",
      "        assert type(X) is np.ndarray\n",
      "        assert len(X.shape)==2\n",
      "        self.X=X\n",
      "        self.X=th.shared(name='X', value=np.asarray(self.X, \n",
      "                         dtype=th.config.floatX),borrow=True)\n",
      "        #The config.floatX and borrow=True stuff is to get this to run\n",
      "        #fast on the gpu. I recommend just doing this without thinking about\n",
      "        #it until you understand the code as a whole, then learning more\n",
      "        #about gpus and theano.\n",
      "        self.n = X.shape[1]\n",
      "        self.m = X.shape[0]\n",
      "        #Hidden_size is the number of neurons in the hidden layer, an int.\n",
      "        assert type(hidden_size) is int\n",
      "        assert hidden_size > 0\n",
      "        self.hidden_size=hidden_size\n",
      "        initial_W = np.asarray(rng.uniform(\n",
      "                 low=-4 * np.sqrt(6. / (self.hidden_size + self.n)),\n",
      "                 high=4 * np.sqrt(6. / (self.hidden_size + self.n)),\n",
      "                 size=(self.n, self.hidden_size)), dtype=th.config.floatX)\n",
      "        self.W = th.shared(value=initial_W, name='W', borrow=True)\n",
      "        self.b1 = th.shared(name='b1', value=np.zeros(shape=(self.hidden_size,),\n",
      "                            dtype=th.config.floatX),borrow=True)\n",
      "        self.b2 = th.shared(name='b2', value=np.zeros(shape=(self.n,),\n",
      "                            dtype=th.config.floatX),borrow=True)\n",
      "        self.activation_function=activation_function\n",
      "        self.output_function=output_function\n",
      "                     \n",
      "    def train(self, n_epochs=100, mini_batch_size=1, learning_rate=0.1):\n",
      "        index = T.lscalar()\n",
      "        x=T.matrix('x')\n",
      "        params = [self.W, self.b1, self.b2]\n",
      "        hidden = self.activation_function(T.dot(x, self.W)+self.b1)\n",
      "        output = T.dot(hidden,T.transpose(self.W))+self.b2\n",
      "        output = self.output_function(output)\n",
      "         \n",
      "        #Use cross-entropy loss.\n",
      "        L = -T.sum(x*T.log(output) + (1-x)*T.log(1-output), axis=1)\n",
      "        cost=L.mean()       \n",
      "        updates=[]\n",
      "         \n",
      "        #Return gradient with respect to W, b1, b2.\n",
      "        gparams = T.grad(cost,params)\n",
      "         \n",
      "        #Create a list of 2 tuples for updates.\n",
      "        for param, gparam in zip(params, gparams):\n",
      "            updates.append((param, param-learning_rate*gparam))\n",
      "         \n",
      "        #Train given a mini-batch of the data.\n",
      "        train = th.function(inputs=[index], outputs=[cost], updates=updates,\n",
      "                            givens={x:self.X[index:index+mini_batch_size,:]})\n",
      "                             \n",
      " \n",
      "        import time\n",
      "        start_time = time.clock()\n",
      "        for epoch in xrange(n_epochs):\n",
      "            print \"Epoch:\",epoch\n",
      "            for row in xrange(0,self.m, mini_batch_size):\n",
      "                train(row)\n",
      "        end_time = time.clock()\n",
      "        print \"Average time per epoch=\", (end_time-start_time)/n_epochs\n",
      "                    \n",
      "    def get_hidden(self,data):\n",
      "        x=T.dmatrix('x')\n",
      "        hidden = self.activation_function(T.dot(x,self.W)+self.b1)\n",
      "        transformed_data = th.function(inputs=[x], outputs=[hidden])\n",
      "        return transformed_data(data)\n",
      "     \n",
      "    def get_weights(self):\n",
      "        return [self.W.get_value(), self.b1.get_value(), self.b2.get_value()]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cPickle\n",
      "import gzip\n",
      "import os\n",
      "from lasagne import easy\n",
      "import lasagne\n",
      "import lasagne.data\n",
      "\n",
      "\n",
      "def load_data(dataset):\n",
      "    ''' Loads the dataset\n",
      " \n",
      "    :type dataset: string\n",
      "    :param dataset: the path to the dataset (here MNIST)\n",
      "    '''\n",
      " \n",
      "    #############\n",
      "    # LOAD DATA #\n",
      "    #############\n",
      " \n",
      "    # Download the MNIST dataset if it is not present\n",
      "    data_dir, data_file = os.path.split(dataset)\n",
      "    if data_dir == \"\" and not os.path.isfile(dataset):\n",
      "        # Check if dataset is in the data directory.\n",
      "        new_path = os.path.join(os.path.split(__file__)[0], \"..\", \"data\", dataset)\n",
      "        if os.path.isfile(new_path) or data_file == 'mnist.pkl.gz':\n",
      "            dataset = new_path\n",
      " \n",
      "    if (not os.path.isfile(dataset)) and data_file == 'mnist.pkl.gz':\n",
      "        import urllib\n",
      "        origin = 'http://www.iro.umontreal.ca/~lisa/deep/data/mnist/mnist.pkl.gz'\n",
      "        print 'Downloading data from %s' % origin\n",
      "        urllib.urlretrieve(origin, dataset)\n",
      " \n",
      "    print '... loading data'\n",
      "    \n",
      "    # Load the dataset\n",
      "    f = gzip.open(dataset, 'rb')\n",
      "    train_set, valid_set, test_set = cPickle.load(f)\n",
      "    f.close()\n",
      "    #train_set, valid_set, test_set format: tuple(input, target)\n",
      "    #input is an numpy.ndarray of 2 dimensions (a matrix)\n",
      "    #which row's correspond to an example. target is a\n",
      "    #numpy.ndarray of 1 dimensions (vector)) that have the same length as\n",
      "    #the number of rows in the input. It should give the target\n",
      "    #target to the example with the same index in the input.\n",
      "    \n",
      "    return (train_set, valid_set, test_set)\n",
      "\n",
      "path= os.path.join(os.getenv(\"DATA_PATH\"), \"mnist\", \"mnist.pkl.gz\")\n",
      "data=load_data(path)\n",
      "print '... done.'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "... loading data\n",
        "... done."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def plot_first_k_numbers(X,k):\n",
      "    from matplotlib import pyplot\n",
      "    import matplotlib as mpl\n",
      "    m=X.shape[0]\n",
      "    k=min(m,k)\n",
      "    j = int(round(k / 10.0))\n",
      "     \n",
      "    fig, ax = pyplot.subplots(j,10)\n",
      "    \n",
      "    for i in range(k):\n",
      " \n",
      "        w=X[i,:]\n",
      " \n",
      "         \n",
      "        w=w.reshape(28,28)\n",
      "        ax[i/10, i%10].imshow(w,cmap=pyplot.cm.gist_yarg,\n",
      "                      interpolation='nearest', aspect='equal')\n",
      "        ax[i/10, i%10].axis('off')\n",
      " \n",
      "     \n",
      "    pyplot.tick_params(\\\n",
      "        axis='x',          # changes apply to the x-axis\n",
      "        which='both',      # both major and minor ticks are affected\n",
      "        bottom='off',      # ticks along the bottom edge are off\n",
      "        top='off',         # ticks along the top edge are off\n",
      "        labelbottom='off')\n",
      "    pyplot.tick_params(\\\n",
      "        axis='y',          # changes apply to the x-axis\n",
      "        which='both',      # both major and minor ticks are affected\n",
      "        left='off', \n",
      "        right='off',    # ticks along the top edge are off\n",
      "        labelleft='off')\n",
      "     \n",
      "    fig.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def m_test(data):\n",
      "    X=data[0][0]\n",
      "    activation_function = T.nnet.sigmoid\n",
      "    output_function=activation_function\n",
      "    A = AutoEncoder(X, 500, activation_function, output_function)\n",
      "    A.train(20,20)\n",
      "    W=np.transpose(A.get_weights()[0])\n",
      "    plot_first_k_numbers(W, 100)\n",
      " \n",
      "m_test(data) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch: 0\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 8\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 9\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 11\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 12\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 13\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 14\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 15\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 16\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 17\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 18\n",
        "Epoch:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 19\n",
        "Average time per epoch="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2.6575\n"
       ]
      },
      {
       "ename": "RuntimeError",
       "evalue": "Invalid DISPLAY variable",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-45-4a2a530deb6c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mplot_first_k_numbers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mm_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m<ipython-input-45-4a2a530deb6c>\u001b[0m in \u001b[0;36mm_test\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mW\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mplot_first_k_numbers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mm_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-44-0cd249686d22>\u001b[0m in \u001b[0;36mplot_first_k_numbers\u001b[1;34m(X, k)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m10.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/gridcl/mehdicherti/anaconda/lib/python2.7/site-packages/matplotlib/pyplot.pyc\u001b[0m in \u001b[0;36msubplots\u001b[1;34m(nrows, ncols, sharex, sharey, squeeze, subplot_kw, gridspec_kw, **fig_kw)\u001b[0m\n\u001b[0;32m   1075\u001b[0m         \u001b[0mgridspec_kw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1077\u001b[1;33m     \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mfig_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1078\u001b[0m     \u001b[0mgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSpec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mncols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mgridspec_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1079\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/gridcl/mehdicherti/anaconda/lib/python2.7/site-packages/matplotlib/pyplot.pyc\u001b[0m in \u001b[0;36mfigure\u001b[1;34m(num, figsize, dpi, facecolor, edgecolor, frameon, FigureClass, **kwargs)\u001b[0m\n\u001b[0;32m    432\u001b[0m                                         \u001b[0mframeon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mframeon\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m                                         \u001b[0mFigureClass\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFigureClass\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m                                         **kwargs)\n\u001b[0m\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfigLabel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/gridcl/mehdicherti/anaconda/lib/python2.7/site-packages/matplotlib/backends/backend_qt4agg.pyc\u001b[0m in \u001b[0;36mnew_figure_manager\u001b[1;34m(num, *args, **kwargs)\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[0mFigureClass\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'FigureClass'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFigure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[0mthisFig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFigureClass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_figure_manager_given_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthisFig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/gridcl/mehdicherti/anaconda/lib/python2.7/site-packages/matplotlib/backends/backend_qt4agg.pyc\u001b[0m in \u001b[0;36mnew_figure_manager_given_figure\u001b[1;34m(num, figure)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mCreate\u001b[0m \u001b[0ma\u001b[0m \u001b[0mnew\u001b[0m \u001b[0mfigure\u001b[0m \u001b[0mmanager\u001b[0m \u001b[0minstance\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mfigure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \"\"\"\n\u001b[1;32m---> 54\u001b[1;33m     \u001b[0mcanvas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFigureCanvasQTAgg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mFigureManagerQT\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/gridcl/mehdicherti/anaconda/lib/python2.7/site-packages/matplotlib/backends/backend_qt4agg.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, figure)\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mDEBUG\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m             \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'FigureCanvasQtAgg: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[0mFigureCanvasQT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m         \u001b[0mFigureCanvasAgg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drawRect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/gridcl/mehdicherti/anaconda/lib/python2.7/site-packages/matplotlib/backends/backend_qt4.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, figure)\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mDEBUG\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'FigureCanvasQt qt4: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m         \u001b[0m_create_qApp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;31m# Note different super-calling style to backend_qt5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/gridcl/mehdicherti/anaconda/lib/python2.7/site-packages/matplotlib/backends/backend_qt5.pyc\u001b[0m in \u001b[0;36m_create_qApp\u001b[1;34m()\u001b[0m\n\u001b[0;32m    137\u001b[0m                 \u001b[0mdisplay\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'DISPLAY'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mdisplay\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m':\\d'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Invalid DISPLAY variable'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m             \u001b[0mqApp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mQtWidgets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mQApplication\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mRuntimeError\u001b[0m: Invalid DISPLAY variable"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}