!obj:pylearn2.train.Train {
    dataset: &train !obj:pylearn2.datasets.fonts.Fonts {
            kind: 'all',
            labels_kind: 'letters',
            start: 0,
            stop: 26800
#            accept_only: ".*-a-.*"
    },
    model: !obj:pylearn2.models.mlp.MLP {
        batch_size: 100,
        
 #       input_space: !obj:pylearn2.space.Conv2DSpace {
 #           shape: [16, 16],
 #           num_channels: 1
 #       },
#        layers: [ !obj:pylearn2.models.mlp.ConvRectifiedLinear {
#                     layer_name: 'h0',
#                     output_channels: 32,
#                     irange: .05,
#                     kernel_shape: [3, 3],
#                     pool_shape: [2, 2],
#                     pool_stride: [1, 1],
#                     #max_kernel_norm: 1.9365
#                 }, !obj:pylearn2.models.mlp.ConvRectifiedLinear {
#                     layer_name: 'h1',
#                     output_channels: 64,
#                     irange: .05,
#                     kernel_shape: [3, 3],
#                     pool_shape: [1, 1],
#                     pool_stride: [1, 1],
#                     #max_kernel_norm: 1.9365
#                 }, !obj:pylearn2.models.mlp.Softmax {
#                     #max_col_norm: 1.9365,
#                     layer_name: 'y',
#                     n_classes: 26,
#                     irange : 0
#                     #istdev: .05
#                 }
#        ],

    
        layers: [
            !obj:pylearn2.models.mlp.RectifiedLinear {
                layer_name: 'h0',
                dim : 300,
                irange : 0.01,
            },
            !obj:pylearn2.models.mlp.RectifiedLinear {
                layer_name: 'h1',
                dim : 100,
                irange : 0.01,
            },
            !obj:pylearn2.models.mlp.Softmax {
                layer_name: 'y',
                n_classes: 26,
                irange: 0
            }
 
        ],
        nvis: 256
    },
    algorithm: !obj:pylearn2.training_algorithms.sgd.SGD {
        learning_rate : 0.000001,
        batch_size : 100,
        monitoring_batches : 10,
        monitoring_dataset : {
            'train': *train,
            'valid': !obj:pylearn2.datasets.fonts.Fonts {
                kind: 'all',
                labels_kind: 'letters',
                start: 26800,
                stop: 30200
            },

            'test': !obj:pylearn2.datasets.fonts.Fonts {
                kind: 'all',
                labels_kind: 'letters',
                start: 30200,
                stop: 33500
            },



        },

        cost : !obj:pylearn2.costs.cost.SumOfCosts {
            costs: [
                !obj:pylearn2.costs.mlp.Default {},
#                !obj:pylearn2.costs.mlp.WeightDecay {
#                    coeffs: [0.00001, 0.000001, 0.000001],
#                },
#                !obj:pylearn2.costs.mlp.dropout.Dropout {
#                    input_include_probs : {'h0': .5, 'h1': .5},
                    #input_scales : {'h0': 1.25}
#                }
            ]
       },

       #cost : !obj:pylearn2.costs.autoencoder.MeanSquaredReconstructionError {},
       #cost : !ob
        #learning_rule : !obj:pylearn2.training_algorithms.learning_rule.Momentum {
        #    init_momentum : 0.5,
        #    nesterov_momentum : true
        #},
        learning_rule: !obj:pylearn2.training_algorithms.learning_rule.AdaDelta {},

   update_callbacks:[
    !obj:pylearn2.training_algorithms.sgd.ExponentialDecay {
        decay_factor: 1.000001,
        min_lr: 1e-15
    }
   ],

       termination_criterion: !obj:pylearn2.termination_criteria.And {
            criteria: [
                !obj:pylearn2.termination_criteria.MonitorBased {
                    channel_name: "valid_y_misclass",
                    prop_decrease: 0.,
                    N: 50
                },
                !obj:pylearn2.termination_criteria.EpochCounter {
                    max_epochs: 150
                }
            ]
        }


    },

    extensions: [ 
#        !obj:pylearn2.training_algorithms.learning_rule.MomentumAdjustor {
#            start: 20,
#            saturate: 100,
#            final_momentum: .9
#        }
    ],

    save_freq: 1,
    save_path: "model_supervised.pkl"

}
